"use strict";(self.webpackChunk_elizaos_docs=self.webpackChunk_elizaos_docs||[]).push([[19837],{43219:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>c,contentTitle:()=>o,default:()=>p,frontMatter:()=>a,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"@elizaos/namespaces/v2/interfaces/DetokenizeTextParams","title":"DetokenizeTextParams","description":"@elizaos/core / v2 / DetokenizeTextParams","source":"@site/api/@elizaos/namespaces/v2/interfaces/DetokenizeTextParams.md","sourceDirName":"@elizaos/namespaces/v2/interfaces","slug":"/@elizaos/namespaces/v2/interfaces/DetokenizeTextParams","permalink":"/api/@elizaos/namespaces/v2/interfaces/DetokenizeTextParams","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{},"sidebar":"defaultSidebar","previous":{"title":"DeriveKeyAttestationData","permalink":"/api/@elizaos/namespaces/v2/interfaces/DeriveKeyAttestationData"},"next":{"title":"DirectoryItem","permalink":"/api/@elizaos/namespaces/v2/interfaces/DirectoryItem"}}');var i=n(31085),r=n(71184);const a={},o="Interface: DetokenizeTextParams",c={},l=[{value:"Properties",id:"properties",level:2},{value:"tokens",id:"tokens",level:3},{value:"modelType",id:"modeltype",level:3}];function d(e){const s={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",p:"p",strong:"strong",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.a,{href:"/api/",children:"@elizaos/core"})," / ",(0,i.jsx)(s.a,{href:"/api/@elizaos/namespaces/v2/",children:"v2"})," / DetokenizeTextParams"]}),"\n",(0,i.jsx)(s.header,{children:(0,i.jsx)(s.h1,{id:"interface-detokenizetextparams",children:"Interface: DetokenizeTextParams"})}),"\n",(0,i.jsxs)(s.p,{children:["Defined in: ",(0,i.jsx)(s.a,{href:"https://github.com/sirgawain0x/elizaOS/blob/main/packages/core/src/specs/v2/types.ts#L1416",children:"packages/core/src/specs/v2/types.ts:1416"})]}),"\n",(0,i.jsxs)(s.p,{children:["Parameters for detokenizing text, i.e., converting a sequence of numerical tokens back into a string.\nThis is the reverse operation of tokenization.\nThis structure is used with ",(0,i.jsx)(s.code,{children:"AgentRuntime.useModel"})," when the ",(0,i.jsx)(s.code,{children:"modelType"})," is ",(0,i.jsx)(s.code,{children:"ModelType.TEXT_TOKENIZER_DECODE"}),"."]}),"\n",(0,i.jsx)(s.h2,{id:"properties",children:"Properties"}),"\n",(0,i.jsx)(s.h3,{id:"tokens",children:"tokens"}),"\n",(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"tokens"}),": ",(0,i.jsx)(s.code,{children:"number"}),"[]"]}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:["Defined in: ",(0,i.jsx)(s.a,{href:"https://github.com/sirgawain0x/elizaOS/blob/main/packages/core/src/specs/v2/types.ts#L1418",children:"packages/core/src/specs/v2/types.ts:1418"})]}),"\n",(0,i.jsx)(s.p,{children:"An array of numerical tokens to be converted back into text."}),"\n",(0,i.jsx)(s.hr,{}),"\n",(0,i.jsx)(s.h3,{id:"modeltype",children:"modelType"}),"\n",(0,i.jsxs)(s.blockquote,{children:["\n",(0,i.jsxs)(s.p,{children:[(0,i.jsx)(s.strong,{children:"modelType"}),": ",(0,i.jsx)(s.code,{children:"string"})]}),"\n"]}),"\n",(0,i.jsxs)(s.p,{children:["Defined in: ",(0,i.jsx)(s.a,{href:"https://github.com/sirgawain0x/elizaOS/blob/main/packages/core/src/specs/v2/types.ts#L1420",children:"packages/core/src/specs/v2/types.ts:1420"})]}),"\n",(0,i.jsx)(s.p,{children:"The model type used for detokenization, ensuring consistency with the original tokenization."})]})}function p(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,i.jsx)(s,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},71184:(e,s,n)=>{n.d(s,{R:()=>a,x:()=>o});var t=n(14041);const i={},r=t.createContext(i);function a(e){const s=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(s):{...s,...e}},[s,e])}function o(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),t.createElement(r.Provider,{value:s},e.children)}}}]);